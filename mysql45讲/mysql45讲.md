- [[#一、索引的常见模型|一、索引的常见模型]]
- [[#二、InnoDB的索引模型|二、InnoDB的索引模型]]
- [[#三、索引选择原则|三、索引选择原则]]
- [[#四、重建索引|四、重建索引]]
- [[#小结|小结]]
- [[#1. **搜索效率高**|1. **搜索效率高**]]
- [[#3. **范围查询和排序**|3. **范围查询和排序**]]
- [[#4. **更好的空间利用**|4. **更好的空间利用**]]
- [[#5. **插入和删除操作**|5. **插入和删除操作**]]
- [[#6. **对比其他索引结构**|6. **对比其他索引结构**]]
- [[#索引深入浅出（下）——大纲和要点总结|索引深入浅出（下）——大纲和要点总结]]
	- [[#索引深入浅出（下）——大纲和要点总结#1. **基本索引操作过程**|1. **基本索引操作过程**]]
	- [[#索引深入浅出（下）——大纲和要点总结#2. **回表与覆盖索引**|2. **回表与覆盖索引**]]
	- [[#索引深入浅出（下）——大纲和要点总结#3. **联合索引与冗余索引**|3. **联合索引与冗余索引**]]
	- [[#索引深入浅出（下）——大纲和要点总结#4. **最左前缀原则**|4. **最左前缀原则**]]
	- [[#索引深入浅出（下）——大纲和要点总结#5. **索引下推优化（Index Condition Pushdown, ICP）**|5. **索引下推优化（Index Condition Pushdown, ICP）**]]
	- [[#索引深入浅出（下）——大纲和要点总结#6. **总结与小结**|6. **总结与小结**]]
	- [[#索引深入浅出（下）——大纲和要点总结#二、全局锁|二、全局锁]]
	- [[#索引深入浅出（下）——大纲和要点总结#三、表级锁|三、表级锁]]
	- [[#索引深入浅出（下）——大纲和要点总结#四、小结|四、小结]]
	- [[#索引深入浅出（下）——大纲和要点总结#五、互动与思考题|五、互动与思考题]]
- [[#关键要点|关键要点]]
- [[#建议阅读与复习|建议阅读与复习]]
	- [[#建议阅读与复习#1. **引言**|1. **引言**]]
	- [[#建议阅读与复习#2. **InnoDB 行锁简介**|2. **InnoDB 行锁简介**]]
	- [[#建议阅读与复习#3. **两阶段锁协议**|3. **两阶段锁协议**]]
	- [[#建议阅读与复习#4. **死锁和死锁检测**|4. **死锁和死锁检测**]]
	- [[#建议阅读与复习#5. **如何减少死锁和优化性能？**|5. **如何减少死锁和优化性能？**]]
	- [[#建议阅读与复习#6. **总结**|6. **总结**]]
	- [[#建议阅读与复习#7. **问题留给读者**|7. **问题留给读者**]]
- [[#1. **直接执行 `delete from T limit 10000;`**|1. **直接执行 `delete from T limit 10000;`**]]
- [[#2. **循环执行 20 次 `delete from T limit 500;`**|2. **循环执行 20 次 `delete from T limit 500;`**]]
- [[#3. **在 20 个连接中同时执行 `delete from T limit 500;`**|3. **在 20 个连接中同时执行 `delete from T limit 500;`**]]
- [[#答案：|答案：]]
- [[#1. 插入数据优化|1. 插入数据优化]]
- [[#1. 插入数据优化#一次性插入多条记录|一次性插入多条记录]]
- [[#1. 插入数据优化#大批量数据插入优化|大批量数据插入优化]]
- [[#2. 主键优化|2. 主键优化]]
- [[#3. 排序优化|3. 排序优化]]
- [[#3. 排序优化#MySQL 两种排序方式|MySQL 两种排序方式]]
- [[#3. 排序优化#排序优化原则|排序优化原则]]
- [[#4. Group By 优化|4. Group By 优化]]
- [[#5. LIMIT 分页查询优化|5. LIMIT 分页查询优化]]
- [[#6. COUNT 优化|6. COUNT 优化]]
- [[#7. UPDATE 操作优化|7. UPDATE 操作优化]]
- [[#总结与提升|总结与提升]]






# 04 深入浅出索引 上
### 一、索引的常见模型

1. **哈希表**

    - 结构：键 - 值存储
    - 优点：快速等值查询
    - 缺点：范围查询效率低
    - 适用场景：等值查询
2. **有序数组**
    - 结构：按顺序存储，支持二分查找
    - 优点：高效等值和范围查询，时间复杂度 $O(\log(N))$
    - 缺点：插入操作开销大
    - 适用场景：静态存储（不常修改的数据）
3. **二叉搜索树**
    - 特点：左子树小于父节点，右子树大于父节点
    - 优点：查询和更新时间复杂度 $O(\log(N))$
    - 缺点：树高对查询效率影响，磁盘访问性能差
    - 发展为多叉树（N叉树）以减少磁盘访问

### 二、InnoDB的索引模型

1. **B+树索引**
    
    - 组织方式：主键索引（聚簇索引）与非主键索引（二级索引）
    - 主键索引：叶子节点存储整行数据
    - 非主键索引：叶子节点存储主键值
    - 查询过程：主键索引直接查找，非主键索引需要“回表”
2. **索引维护**
    
    - 插入数据时的页分裂和合并
    - 性能影响与空间利用率
    - 自增主键的优点：减少插入时的移动与分裂

### 三、索引选择原则

- **自增主键 vs 业务字段主键**
    - **存储空间与性能的权衡**：自增主键通常占用较小的存储空间，并且由于其递增特性，能减少B+树索引的页分裂，提高查询和插入性能；业务字段主键可能较大且不连续，增加索引的存储开销和维护成本。
    - **适用场景的分析**：在数据模型中，若业务字段具有唯一性且较小且不频繁变化，可以考虑作为主键；否则，使用自增主键作为内部标识符更为高效和灵活。
    - **总结**：在选择主键时，应权衡存储空间和性能，通常自增主键更适合大多数场景，而业务字段主键适用于特定需求。

### 四、重建索引

- **主键索引与普通索引重建的注意事项**
    
    - **主键索引**：由于聚簇索引决定了数据的物理存储顺序，重建主键索引需要谨慎，可能涉及大量数据移动，应在低峰期进行。
    - **普通索引**：二级索引的重建相对独立，不会直接影响数据的物理存储，但仍需考虑索引的大小和重建时的资源消耗。
    - **总结**：重建索引需区分主键和普通索引的不同影响，谨慎操作以避免对数据存储和查询性能造成负面影响。
- **性能影响与最佳实践**
    
    - **性能影响**：重建索引会占用系统资源，可能导致临时的性能下降，应合理安排重建时间。
    - **最佳实践**：在重建索引前进行备份，选择适当的工具和方法（如在线重建），并在业务低峰期执行，以最小化对系统的影响。
    - **总结**：重建索引时应遵循最佳实践，合理安排以确保系统稳定性和最小化性能影响。

### 小结

- 综述B+树索引的性能优越性
- 建议使用自增主键以优化空间和性能
- 留下思考问题，鼓励读者参与讨论

### Mysql b+树
![[Pasted image 20240926001539.png]]


## 索引类型
![[Pasted image 20240926002639.png|500]]
![[Pasted image 20240926002812.png|500]]
# 05深入浅出索引 下
### 索引深入浅出（下）——大纲和要点总结

#### 1. **基本索引操作过程**

- **问题描述**：在 `select * from T where k between 3 and 5` 查询中，需要几次树的搜索操作？涉及到几次回表操作？
- **示例分析**：
    - 通过 **k 索引树** 定位到 k=3 和 k=5 的记录。
    - 通过主键 ID 进行回表，获取对应的记录数据。
    - 总共涉及 **3 次索引读取** 和 **2 次回表**。

#### 2. **回表与覆盖索引**

- **回表**：在二级索引（非聚簇索引）中，如果需要的字段不在索引中，必须通过主键再次访问主表获取完整数据，这个过程称为 **回表**。
- **覆盖索引**：如果查询所需的字段全部包含在索引中，则可以避免回表直接返回数据。这种情况称为 **覆盖索引**。
    - 优点：减少回表次数，提升查询性能。
    - 示例：`select ID from T where k between 3 and 5` 只需要读取 k 索引上的 ID，不需要回表。

#### 3. **联合索引与冗余索引**

- **问题描述**：是否有必要为市民信息表创建 `(身份证号, 姓名)` 的联合索引？
- **解答**：如果有高频查询是基于 **身份证号查询姓名** 的场景，联合索引有助于覆盖查询，减少回表。然而，建立冗余索引的代价较高，需要根据业务需求权衡是否增加冗余索引。

#### 4. **最左前缀原则**

- **概念**：在联合索引中，B+树索引可以通过 **最左前缀** 来加速检索，即可以使用索引的最左边 N 个字段或最左 M 个字符进行快速定位。
- **示例分析**：
    - 联合索引 `(name, age)` 可以用于 `where name = '张三'` 的查询，也可以用于 `where name like '张%'` 的范围查询。
    - **字段顺序的设计**：如果一个联合索引能够通过调整字段顺序减少索引维护成本，那么应优先考虑这一调整。比如 `(name, age)` 索引可以加速基于 `name` 的查询，不必再为 `name` 单独建立索引。

#### 5. **索引下推优化（Index Condition Pushdown, ICP）**

- **问题描述**：在联合索引 `(name, age)` 上的复杂查询，如何减少不必要的回表操作？
- **概念**：MySQL 5.6 引入的 **索引下推优化** 允许在索引遍历过程中，对索引中包含的字段先做过滤判断，避免回表。只有符合条件的记录才会回表，减少回表次数。
- **示例**：
    - SQL：`select * from tuser where name like '张%' and age = 10 and ismale = 1`
    - 在没有索引下推的情况下，会对所有 `name like '张%'` 的记录逐条回表。
    - 在有索引下推的情况下，InnoDB 在索引内部先过滤 `age = 10`，减少回表次数。

#### 6. **总结与小结**

- **关键概念**：
    - 回表：通过主键访问主表获取完整数据的过程。
    - 覆盖索引：索引包含查询所需的全部字段，避免回表。
    - 最左前缀原则：联合索引从最左侧字段开始使用，提升索引复用效率。
    - 索引下推：通过索引字段的提前过滤，减少回表次数。
- **数据库设计原则**：在满足业务需求的前提下，尽量减少资源消耗。根据高频查询需求，合理设计索引顺序与覆盖索引，优化查询效率。



# 06总结大纲和要点: 全局锁和表锁 —— 给表加个字段怎么有这么多阻碍？
---
#### 二、全局锁
- **定义**: 对整个数据库实例加锁。
- **加锁方法**: `FLUSH TABLES WITH READ LOCK (FTWRL)`
- **主要应用场景**: 全库逻辑备份，确保备份期间数据库处于只读状态。
- **风险与限制**:
    - 主库备份时，更新操作被阻塞，可能导致业务停摆。
    - 从库备份时，binlog同步被阻塞，导致主从延迟。
- **替代方法**: 使用 `mysqldump` 的 `--single-transaction` 参数，适用于支持事务的引擎（如 InnoDB）。
- **为何不使用 `SET GLOBAL READONLY=true`**:
    1. 可能影响系统中其他依赖 `readonly` 状态的逻辑。
    2. 异常断开时，全局锁会自动释放，而 `readonly` 状态则可能长期保持，增加风险。
#### 三、表级锁
- **分类**: 表锁和元数据锁（MDL）。
    
    **1. 表锁**
    
    - **语法**: `LOCK TABLES ... READ/WRITE`，`UNLOCK TABLES` 释放锁。
    - **作用**: 限制其他线程对指定表的读写操作，同时限制当前线程的操作范围。
    - **使用场景**: 主要用于不支持行锁的存储引擎（如 MyISAM）。
    - **注意事项**: 对 InnoDB 引擎不推荐使用，因锁粒度过大影响并发性能。
    
    **2. 元数据锁（MDL）**
    
    - **定义**: 自动加锁，确保读写操作的正确性。
    - **作用**:
        - 对表的增删改查操作加 MDL 读锁。
        - 对表结构变更操作加 MDL 写锁。
    - **锁的互斥关系**:
        - 读锁之间不互斥，可并行执行。
        - 读写锁、写锁之间互斥，确保表结构变更的安全性。
    - **实例分析**:
        - 在进行表结构变更时，如添加字段，即使是小表，也可能因 MDL 锁导致整个表的查询和更新被阻塞，进而可能导致数据库挂起。
    - **安全操作建议**:
        - 避免长事务占用 MDL 锁，必要时暂停或终止长事务。
        - 对于高频访问的热点表，使用 `ALTER TABLE ... NOWAIT/WAIT n` 语法（MariaDB 和 AliSQL 支持）设定等待时间，避免长时间阻塞。
#### 四、小结
- **全局锁**:
    - 适用于逻辑备份，但需谨慎使用，优先选择 `--single-transaction` 参数的备份方法。
    - 避免使用 `SET GLOBAL READONLY=true`，推荐使用 `FTWRL`。
- **表级锁**:
    - 仅在不支持行锁的存储引擎中使用。
    - 避免在高并发场景下使用 `LOCK TABLES`，优先依赖 InnoDB 的行锁机制。
    - 注意 MDL 锁的影响，确保表结构变更不会影响线上查询和更新。
#### 五、互动与思考题

- **思考题**:
    - 备库使用 `--single-transaction` 备份时，主库进行 DDL 操作，备库会出现何种现象？
- **评论区精选**:
    - 用户提问和作者回复，深入讨论了 MDL 锁的行为及其在不同场景下的表现。

---

### 关键要点

1. **锁的分类**: MySQL中的锁分为全局锁、表级锁和行锁，本文重点讨论全局锁和表级锁。
2. **全局锁的使用与风险**:
    - 通过 `FTWRL` 实现全库只读，适用于逻辑备份。
    - 备份期间可能导致业务停摆或主从延迟。
    - 推荐使用支持事务的 `--single-transaction` 备份方法。
3. **表级锁的类型与应用**:
    - **表锁**: 通过 `LOCK TABLES` 控制，适用于不支持行锁的存储引擎，但对 InnoDB 不推荐。
    - **MDL**: 自动管理，确保表操作的一致性，需注意其在高并发或表结构变更时的影响。
4. **安全操作建议**:
    - 尽量使用行锁机制（如 InnoDB）以提高并发性能。
    - 在进行 DDL 操作时，使用 `NOWAIT/WAIT n` 语法避免长时间阻塞。
    - 监控和管理事务，防止长事务占用 MDL 锁导致系统挂起。
5. **实际案例分析**:
    - 通过具体示例说明全局锁和表级锁在备份和 DDL 操作中的表现及潜在问题。

---

### 建议阅读与复习

- **下一篇文章**: 行锁的详细介绍。
- **相关知识**: 事务隔离级别，特别是可重复读隔离级别下的一致性视图。
- **工具使用**: 熟悉 `mysqldump` 的不同参数及其适用场景。


# **07 | 行锁功过：怎么减少行锁对性能的影响？**

#### 1. **引言**

- 行锁是 MySQL 引擎层实现的锁机制，InnoDB 支持行锁，MyISAM 只支持表锁。
- 行锁有助于提高并发处理能力，而表锁会影响业务并发度。

#### 2. **InnoDB 行锁简介**

- InnoDB 支持行级锁，允许并发事务访问不同的行。
- 如果多个事务更新同一行，后来的事务会被阻塞，直到前一个事务提交或回滚。

#### 3. **两阶段锁协议**

- **加锁时机**：行锁在操作需要时才加锁。
- **锁释放时机**：行锁在事务结束（commit 或 rollback）时才释放，而不是操作结束时释放。
- **优化策略**：如果事务中涉及多个行的更新，应该将可能引起锁冲突的更新操作尽量放到事务的后面，减少锁的持有时间，从而提升并发度。

**示例**：在线电影票交易业务

- 操作涉及更新顾客账户余额、影院账户余额、插入交易日志。
- 为了减少锁冲突，将对影院账户余额的更新放到最后进行（最可能冲突的行锁操作尽量后置）。

#### 4. **死锁和死锁检测**

- **死锁定义**：当多个事务互相等待对方释放资源时，系统进入死锁状态。
    
- **两种死锁解决策略**：
    
    1. **超时等待**：通过设置 `innodb_lock_wait_timeout` 参数来定义超时回滚时间（默认50秒）。
    2. **死锁检测**：启用死锁检测，检测到死锁时回滚其中一个事务，以避免无限等待。
- **死锁检测的额外负担**：死锁检测的复杂度是 O(n)，在高并发场景下（如多个事务同时更新同一行数据）会消耗大量 CPU 资源，导致性能瓶颈。
    

#### 5. **如何减少死锁和优化性能？**

1. **关闭死锁检测（风险高）**：如果确保业务不会产生死锁，可以临时关闭死锁检测（`innodb_deadlock_detect` 设为 OFF）。但如果出现死锁，会导致超时回滚，增加业务风险。
    
2. **控制并发度**：减少访问相同数据行的并发事务数。可以通过客户端或中间件层面控制，但在客户端并发数较多时，仍可能导致服务器端并发过高。
    
3. **逻辑分片减少锁冲突**：将热点数据（如影院账户余额）分成多条记录，更新时随机选择一条记录更新，减少并发事务访问同一行的概率，从而降低锁竞争和死锁检测的开销。
    
    - 示例：影院账户余额分为10条记录，随机更新其中一条，减少并发冲突的概率。

#### 6. **总结**

- 行锁能够提升并发度，但可能导致锁冲突和死锁问题。
- 两阶段锁协议下，操作的顺序设计很重要，应该将冲突可能性大的锁操作尽量后置，减少锁的持有时间。
- 死锁检测是应对死锁的有效机制，但在高并发下可能带来性能开销，优化措施包括关闭检测、控制并发、使用逻辑分片。

#### 7. **问题留给读者**

- 如果需要删除表中的前 10000 行数据，选择以下哪种方式？为什么？
    1. 直接执行 `delete from T limit 10000;`
    2. 循环执行20次 `delete from T limit 500;`
    3. 在20个连接中同时执行 `delete from T limit 500;`


对于最后的问题，删除表中前 10,000 行数据的三种方式，每种方式的优缺点如下：

### 1. **直接执行 `delete from T limit 10000;`**

- **优点**：单次操作，语句简单，不需要额外的控制逻辑。
- **缺点**：一次性删除大量数据，可能导致锁表时间过长，特别是当表非常大时。大批量删除还会消耗大量资源（如 I/O 和内存），影响其他并发操作。

### 2. **循环执行 20 次 `delete from T limit 500;`**

- **优点**：通过多次删除操作，将大批量删除分散为小批量删除，减少了单次操作的负载和锁定时间，降低了对其他并发事务的影响。
- **缺点**：需要在代码层面实现循环逻辑，数据库执行20次操作，操作次数较多，增加了一定的开销。

### 3. **在 20 个连接中同时执行 `delete from T limit 500;`**

- **优点**：通过并行化操作，删除数据的速度会更快，操作在多个连接中同时进行，理论上可以更好地利用系统资源，降低整体删除时间。
- **缺点**：并发连接同时删除数据，可能会产生**行锁冲突**，导致部分操作被阻塞或回滚。如果不处理好并发事务的协调，可能带来额外的死锁或性能问题。此外，多连接并发也会增加系统的负载，可能对其他操作产生影响。

### 答案：

**推荐第二种方法**——**循环执行 20 次 `delete from T limit 500;`**。

这是因为：

- 小批量删除能够有效减少锁定时间，降低单次操作对系统性能的影响。
- 同时，它不会像并发删除那样容易造成行锁冲突或死锁问题。
- 比起一次性删除大量数据，它更容易被 MySQL 处理，避免造成 I/O 和内存的过载。

尽管并行删除在某些特定场景下可能更快，但风险更大，因此第二种方式在绝大多数场景下是更稳定、合理的选择。


# SQL 优化笔记

## 1. 插入数据优化

### 一次性插入多条记录
- **批量插入**: 使用批量插入语法 (`INSERT INTO ... VALUES ...`) 而非逐条插入，减少数据库交互和事务提交，提高性能。
- **手动控制事务**: 大批量插入时，可以手动控制事务，避免每条记录都单独提交事务，提高效率。
- **主键顺序插入**: 使用顺序插入（如 `AUTO_INCREMENT` 自增主键）比乱序插入性能更好，避免索引页分裂。

### 大批量数据插入优化
- **LOAD DATA INFILE**: 使用 `LOAD DATA INFILE` 来进行大规模数据的快速插入。适用于几百万甚至更多记录。
  - 客户端启用 `--local-infile` 参数。
  - 服务端设置 `local_infile = 1`。
  - 语法:
    ```sql
    LOAD DATA LOCAL INFILE '/path/to/file' INTO TABLE table_name 
    FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n';
    ```

## 2. 主键优化
- **顺序插入**: 使用 `AUTO_INCREMENT` 自增主键，避免使用 UUID 或自然主键，减少页分裂。
- **降低主键长度**: 主键越短，二级索引占用的空间越少，性能更高。
- **避免修改主键**: 修改主键会导致索引重建，影响性能。

## 3. 排序优化

### MySQL 两种排序方式
- **Using Filesort**: 非索引字段排序会使用 `filesort`，需要将数据放入 `sort_buffer` 排序，性能较低。
- **Using Index**: 通过已有索引直接返回有序结果，效率最高。

### 排序优化原则
- **基于排序字段建立索引**: 对排序字段建立合适的索引，尤其是多字段排序时遵循最左前缀法则。
- **覆盖索引**: 使用覆盖索引，避免回表查询，提升性能。
- **多字段排序时注意索引顺序**: 针对多字段排序（如一个升序一个降序）时，创建联合索引时需注意顺序。
- **增大排序缓冲区**: 对大数据量排序，增大 `sort_buffer_size`（默认 256k）提升性能。

## 4. Group By 优化
- **索引优化**: `GROUP BY` 操作可以通过索引提升效率，同样需遵循最左前缀原则。
- **减少 `GROUP BY` 使用**: 应用层处理分组有时更高效。

## 5. LIMIT 分页查询优化
- **问题**: 数据量大时，`LIMIT` 的偏移量越大，查询越慢。
- **优化思路**: 
  - 使用 **覆盖索引** 提升查询性能，避免读取不必要的行。
  - 使用 **子查询** 优化:
    ```sql
    SELECT * FROM tb_sku t, 
    (SELECT id FROM tb_sku ORDER BY id LIMIT 2000000,10) a 
    WHERE t.id = a.id;
    ```

## 6. COUNT 优化
- **性能对比**: 使用 `COUNT(*)` 性能最佳，推荐使用。不同 COUNT 操作的性能排序：
  - `COUNT(字段)` < `COUNT(主键 id)` < `COUNT(1)` ≈ `COUNT(*)`
  - 注意: `COUNT(NULL)` 不会计数。
！！- `COUNT(*)` 是 MySQL 中性能最优的行数统计方法，推荐优先使用。
- `COUNT(字段)` 会过滤掉 `NULL`，并因此增加计算负担，性能相对较差。
- `COUNT(1)` 和 `COUNT(*)` 基本上是等效的，性能相同，具体情况视数据库优化器的行为而定。
- 避免使用 `COUNT(NULL)`，因为它总是返回 `0`。
## 7. UPDATE 操作优化
- **行锁与表锁**: InnoDB 的行锁基于索引，若条件字段没有索引，会导致行锁升级为表锁，影响性能。
  - **索引避免表锁**: 确保 `UPDATE` 条件字段有索引，避免表锁。例如：
    ```sql
    -- 针对主键操作，加行锁
    UPDATE course SET name = 'javaEE' WHERE id = 1;
    -- 针对非索引字段操作，可能加表锁
    UPDATE course SET name = 'SpringBoot' WHERE name = 'PHP';
    ```

## 总结与提升
- **索引设计与使用**: 针对查询频繁的字段建立索引，遵循最左前缀法则，使用覆盖索引减少回表查询。
- **批量操作**: 批量插入、更新或删除操作更高效，手动控制事务提升性能。
- **分页查询优化**: 大数据量情况下，优化 `LIMIT` 查询，避免大量偏移。
- **参数调优**: 根据业务需求适当调整数据库参数，如 `sort_buffer_size` 和 `innodb_buffer_pool_size`。



# 小林

### 为什么 MySQL InnoDB 选择 B+ 树作为索引的数据结构

1. **磁盘 I/O 次数和节点存储密度**：
    - **B+ 树**的所有叶子节点通过链表相连，这使得范围查询（如 `BETWEEN`、`>=`、`<=`）更加高效，因为可以顺序遍历叶子节点而无需频繁回溯树结构。
    - **B 树**的内部节点也存储数据记录，这会增加每个节点的大小，降低缓存命中率，影响性能。
2. **适合大数据量**：
    
    - B+ 树通过增加每个节点的键数量，减少了树的高度，从而降低了查找时需要的磁盘 I/O 次数。这对于大规模数据集尤为重要。
3. **支持范围查询**：
    
    - **B+ 树**可以高效地支持范围查询，因为所有的叶子节点按键值顺序排列，适合需要按顺序检索数据的操作。
    - **Hash 索引**不支持范围查询，只适合等值查询。

### 一句话总结MySQL InnoDB 选择 B+ 树作为索引的数据结构？
首先，B+树不同于B树，它只有叶子节点存储实际数据。这样，非叶子节点的空间可以更多地用于存放索引键，从而容纳更多的子节点，天然降低了树的高度，减少了节点访问次数，也就降低了磁盘I/O的操作次数。其次，B+树的叶子节点通过双向链表相连，使得左右遍历非常快速，极大提高了范围查询的效率。再者，B+树能够在插入和删除操作后自我平衡，保持树的结构稳定性。这保证了操作的时间复杂度在 `O(log n)` 范围内
### 什么时候适用索引

1. **唯一性限制的字段**：
    
    - 如商品编码、用户ID等，这些字段通常用于快速查找和确保数据唯一性。
2. **常用于查询条件的字段**：
    
    - 在 `WHERE` 子句、`GROUP BY`、`ORDER BY` 中频繁使用的字段，使用索引可以显著提高查询性能。

### 什么时候不需要创建索引

1. **查询中不涉及的字段**：
    
    - 如果某个字段在查询中很少或从不使用，那么为其创建索引只会增加存储开销和维护成本。
2. **字段重复度高或数据量较少**：
    
    - 高重复度（低选择性）的字段，如性别、布尔值等，索引效果不佳。
    - 数据量较少时，表扫描的开销可能比索引扫描更低。
3. **经常更新的字段**：
    
    - 索引需要维护，当字段频繁更新时，索引的维护成本较高，可能导致性能下降。

### 什么时候索引会失效

1. **使用模糊查询**：
    
    - 例如 `LIKE '%xx'` 无法使用索引，因为前导字符不确定。
    - `LIKE 'xx%'` 可以使用索引，因为可以利用索引的有序性。
2. **对索引列进行计算、函数或类型转换**：
    
    - 例如 `WHERE YEAR(date_column) = 2024`，这种情况下，索引无法被有效利用。
    - 尽量避免在 `WHERE` 子句中对索引列进行操作。
3. **联合索引不遵循最左前缀匹配原则**：
    
    - 联合索引（如 `(a, b, c)`）在查询时需要从最左边的列开始使用。如果查询条件不包含最左边的列，索引可能无法被使用。
4. **OR 条件中混用索引列和非索引列**：
    
    - 例如 `WHERE a = 1 OR b = 2`，如果 `b` 没有索引，整个查询可能无法有效利用索引。

### 优化索引的方法

1. **使用前缀索引、覆盖索引**：
    
    - **前缀索引**：对于长字符串类型的列，可以只索引前缀部分，减少索引大小，提高性能。
    - **覆盖索引**：查询只涉及索引中的列，避免回表操作，提升查询速度。
2. **设置主键为自增，避免页分裂**：
    
    - 自增主键保证新插入的数据总是按顺序插入，减少页分裂的可能性，提升插入性能。
3. **设置索引列为 NOT NULL**：
    
    - 索引列为 `NOT NULL` 可以简化索引结构，减少存储空间，并提高查询效率。
### 一句话总结优化索引的方法
首先，对于字符串类型的列，采用前缀索引只索引字符串的前缀部分，可以显著减小索引的大小。这不仅允许非叶子节点存储更多的子节点，降低B+树的高度，从而减少查询时的节点访问次数，提高查询效率，还能降低索引的创建和重建成本。其次，通过将主键设置为自增主键，可以确保新插入的数据总是按顺序添加到B+树的最右侧，减少页分裂的可能性，提升插入操作的性能和整体索引的维护效率。最后，将索引列设置为 `NOT NULL`，能够简化索引的存储结构，减少索引的存储空间占用，同时提高查询优化器利用索引的效率，从而进一步提升查询性能。
#### 1 “索引列设置为 `NOT NULL`，能够简化索引的存储结构，减少索引的存储空间占用”****
“null列存在且在8列以内时，天然会在行结构内多一个1字节的字段来表示，使得每一行都会多一字节储存成本”



## InnoDB 是如何存储数据的？
![[Pasted image 20241028205415.png]]![[Pasted image 20241028205418.png]]

### InnoDB 数据存储与页目录

- **数据页**：InnoDB 将数据按 `16KB` 的数据页单位进行存储和读写，每次 I/O 操作处理一个完整的数据页，提高了访问效率。数据页之间以**双向链表**形式逻辑连接。
- **记录组织**：数据页中的记录按主键顺序形成单向链表，为提高查找效率，设计了**页目录**，将记录分组并存储每组的最大主键地址，使用二分查找快速定位记录所在分组。

### B+ 树索引结构

- **B+ 树节点**：InnoDB 采用 B+ 树作为索引，每个节点是一个数据页。B+ 树的叶子节点存储数据或主键，非叶子节点用于索引导航，支持范围查询。
- **查询过程**：查找时从根节点开始，逐层二分查找，最终定位到叶子节点的数据页。在数据页内，通过页目录二分定位到分组，再在分组内查找记录。

### 聚簇索引与二级索引

- **聚簇索引**：叶子节点存储实际数据，每张表只能有一个聚簇索引。若无主键，InnoDB 选择非空唯一列或自动生成自增 ID 作为聚簇索引。
- **二级索引**：叶子节点存储主键值而非实际数据。多个二级索引可用于辅助查询非主键字段。若查询字段在二级索引中存在且无需访问聚簇索引，则称为**索引覆盖**；若查询字段不在二级索引中，需要在聚簇索引查找完整数据行，此过程称为**回表**。


### 一句话总结innodb是如何储存数据的？
首先InnoDB 采用了 B+ 树作为索引，以页作为基本储存单元，默认16kb一页，每个节点都是一个数据页，叶子结点的页与页之间使用双向链表组织，页内部的储存元素的节点之间是单向链表，页内通过批量分组的思想维护了一个页目录，查找方式均通过二分查找。



## 索引失效条件

总结了在 MySQL 中可能导致索引失效的 6 种情况：

1. **模糊匹配**：使用 `LIKE %xx` 或 `LIKE %xx%` 方式会导致索引失效，因为无法有效使用前缀匹配。
2. **索引列使用函数**：在查询条件中对索引列使用函数，会导致无法利用索引。
3. **索引列使用表达式**：如果在查询条件中对索引列进行表达式计算，同样会导致索引失效。
4. **隐式类型转换**：当字符串类型的索引列与数字比较时，MySQL 会将字符串转换为数字。由于隐式类型转换通过 `CAST` 函数实现，相当于对索引列使用了函数，从而导致索引失效。
5. **联合索引的最左匹配原则**：联合索引的匹配需遵循最左匹配原则，否则会导致索引失效。
6. **OR 条件**：如果 `WHERE` 子句中 `OR` 前的条件列是索引列，而 `OR` 后的条件列不是索引列，则会使索引失效。


## 一句话总结MySQL 使用 like “%x“，索引不一定失效的场景是什么
当表中只有主键和被查询的二级索引字段时，使用 `LIKE "%x"` 进行左模糊匹配，索引不一定失效，而是会走二级索引树的全扫描。


总结一下 `count(*)` 和 `count(1)` 的区别以及哪种性能最好。

### 1. **基本结论**

- **`count(*)` 和 `count(1)` 在性能上没有显著差异**。在 `InnoDB` 存储引擎中，它们的处理方式是相同的，官方文档也表明这两者无性能差异。优化器会对它们进行优化，并使用最小的二级索引进行扫描以提高效率。
- **`count(字段)` 的执行效率最差**，尤其在字段非索引的情况下，因为会采用全表扫描来统计非 `NULL` 记录的数量。

### 2. **执行过程分析**

- **`count(1)`**：统计符合条件的记录数，由于 `1` 是一个常量，不会为 `NULL`，因此不需要读取字段的具体值，仅做计数。若表有二级索引，优先使用二级索引扫描，效率相对较高。
- **`count(*)`**：与 `count(1)` 相同，`*` 并不表示读取所有字段，而是由系统处理为一个常量 `0` 来进行计数，同样适用二级索引优化。
- **`count(字段)`**：当指定具体字段时，`count(字段)` 只统计该字段不为 `NULL` 的记录数。此时，如果字段没有索引，会执行全表扫描，效率较低。

### 3. **其他存储引擎的差异**

- 在 `MyISAM` 中，`count(*)` 查询可以直接读取表的 `row_count` 元信息，效率非常高，为 $O(1)$。而 `InnoDB` 由于支持事务和多版本并发控制（MVCC），无法简单维护一个 `row_count`，因此需要遍历表记录来统计行数。

### 4. **大表优化建议**

- **使用近似值**：对统计精度要求不高的场景可以使用 `SHOW TABLE STATUS` 或 `EXPLAIN` 来获取近似行数。
- **使用额外计数表**：对计数要求精确且频繁统计的大表，可以创建一张计数表，在插入和删除记录时同步更新计数值。

总结来看，**`count(*)` 和 `count(1)` 是性能相同的优选方法**，而 `count(字段)` 应谨慎使用，除非必须统计某字段的非 `NULL` 记录数。



# 事物篇
# 事务特性与隔离级别

## 事务的特性

事务是由 MySQL 的引擎来实现的，常见的 InnoDB 引擎支持事务。并不是所有的引擎都能支持事务，例如 MySQL 原生的 MyISAM 引擎就不支持事务。因此，大多数 MySQL 的引擎都是使用 InnoDB。

事务有以下四个特性（ACID）：

### 1. 原子性（Atomicity）
- **定义**：一个事务中的所有操作，要么全部完成，要么全部不完成。事务在执行过程中发生错误，会被回滚到事务开始前的状态。
- **示例**：购买商品时，成功则支付钱并获得商品；失败则商品在商家手中，消费者的钱没有支出。

### 2. 一致性（Consistency）
- **定义**：事务操作前后，数据满足完整性约束，数据库保持一致性状态。
- **示例**：用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元。操作后，用户 A 600 元，用户 B 800 元，总共仍然是 1400 元。

### 3. 隔离性（Isolation）
- **定义**：多个并发事务之间不会相互干扰。每个事务都有一个完整的数据空间，对其他并发事务是隔离的。
- **示例**：一个消费者的购买事务不影响其他消费者的购买。

### 4. 持久性（Durability）
- **定义**：事务处理结束后，对数据的修改是永久的，即便系统故障也不会丢失。

## InnoDB 引擎保证事务特性的技术

- **持久性**：通过 **redo log**（重做日志）来保证。
- **原子性**：通过 **undo log**（回滚日志）来保证。
- **隔离性**：通过 **MVCC**（多版本并发控制）或锁机制来保证。
- **一致性**：通过持久性、原子性和隔离性共同来保证。

## 并发事务引发的问题

在并发处理多个事务时，可能会出现以下问题：

### 1. 脏读（Dirty Read）
- **定义**：一个事务读取到另一个未提交事务修改过的数据。
- **示例**：事务 A 读取小林的余额，事务 B 读取到更新后的余额，即使事务 A 尚未提交。

### 2. 不可重复读（Non-repeatable Read）
- **定义**：在一个事务内多次读取同一数据，前后两次读到的数据不一致。
- **示例**：事务 A 读取小林的余额，事务 B 更新该余额并提交，事务 A 再次读取时发现余额已改变。

### 3. 幻读（Phantom Read）
- **定义**：在一个事务内多次查询某个符合条件的记录数量，前后查询到的记录数量不一样。
- **示例**：事务 A 查询余额大于 100 万的记录，发现有 5 条，事务 B 插入一条记录后，事务 A 再次查询发现有 6 条。

## 事务的隔离级别

根据 SQL 标准，主要有四种事务隔离级别：

### 1. 读未提交（Read Uncommitted）
- **描述**：事务可以读取其他未提交事务的数据。
- **影响**：
  - 脏读：允许。
  - 不可重复读：可能发生。
  - 幻读：可能发生。

### 2. 读已提交（Read Committed）
- **描述**：事务只能读取已提交事务的数据。
- **影响**：
  - 脏读：不允许。
  - 不可重复读：可能发生。
  - 幻读：可能发生。

### 3. 可重复读（Repeatable Read）
- **描述**：在一个事务中，多次读取同一数据结果一致。
- **影响**：
  - 脏读：不允许。
  - 不可重复读：不允许。
  - 幻读：可能发生。

### 4. 串行化（Serializable）
- **描述**：强制事务按顺序执行，完全隔离。
- **影响**：
  - 脏读：不允许。
  - 不可重复读：不允许。
  - 幻读：不允许。

## 总结

选择合适的事务隔离级别需要权衡数据一致性和系统性能。高一致性要求的应用通常选择较高的隔离级别，而对性能要求较高的应用则可以选择较低的隔离级别。

## 事务的隔离级别有哪些？

前面我们提到，当多个事务并发执行时可能会遇到「脏读、不可重复读、幻读」的现象，这些现象会对事务的一致性产生不同程序的影响。

- 脏读：读到其他事务未提交的数据；
- 不可重复读：前后读取的数据不一致；
- 幻读：前后读取的记录数量不一致。

这三个现象的严重性排序如下：
![[Pasted image 20241030164930.png]]
SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：

- **读未提交（_read uncommitted_）**，指一个事务还没提交时，它做的变更就能被其他事务看到；
- **读提交（_read committed_）**，指一个事务提交之后，它做的变更才能被其他事务看到；
- **可重复读（_repeatable read_）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**；
- **串行化（_serializable_ ）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

按隔离水平高低排序如下：![[Pasted image 20241030164936.png]]针对不同的隔离级别，并发事务时可能发生的现象也会不同。![[Pasted image 20241030164944.png]]也就是说：

- 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；
- 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；
- 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；
- 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。

所以，要解决脏读现象，就要升级到「读提交」以上的隔离级别；要解决不可重复读现象，就要升级到「可重复读」的隔离级别，要解决幻读现象不建议将隔离级别升级到「串行化」。

# MySQL 事务与隔离性总结

## 1. 事务概述
事务是在 MySQL 引擎层实现的，常见的 InnoDB 引擎支持事务。事务的四大特性是：

- **原子性**：事务要么全部执行成功，要么全部不执行。
- **一致性**：事务执行前后数据的一致性。
- **隔离性**：并发事务之间的隔离程度。
- **持久性**：事务一旦提交，其结果是永久的。

本次主要讲解的是**隔离性**。

## 2. 隔离性与问题
当多个事务并发执行时，可能会引发以下问题：

- **脏读**：一个事务读取到另一个未提交事务的数据。
- **不可重复读**：同一事务中两次读取数据结果不一致。
- **幻读**：一个事务读取到的行数在同一事务中发生变化。

### 2.1 隔离级别
为了解决上述问题，SQL 提出了四种隔离级别，按隔离程度递增：

1. **读未提交**（Read Uncommitted）
2. **读已提交**（Read Committed）
3. **可重复读**（Repeatable Read）
4. **串行化**（Serializable）

隔离级别越高，性能越差。InnoDB 引擎的默认隔离级别是**可重复读**。

### 2.2 解决方案
- **脏读**：将隔离级别升级到**读已提交**以上。
- **不可重复读**：将隔离级别升级到**可重复读**以上。
- **幻读**：不建议将隔离级别升级到**串行化**，因其会显著降低并发性能。

### 3. InnoDB的隔离性实现

虽然 InnoDB 默认的隔离级别是**可重复读**，但它在很大程度上避免了幻读现象，解决方案包括：

#### 3.1 快照读（普通 SELECT 语句）
通过 **MVCC（多版本并发控制）** 解决幻读问题：

- 在可重复读隔离级别下，事务执行过程中看到的数据与事务启动时的数据一致。
- 即使有其他事务插入新数据，当前事务也无法查询到这些数据，从而避免幻读。

#### 3.2 当前读（SELECT ... FOR UPDATE 等语句）
通过 **next-key lock**（记录锁+间隙锁）解决幻读问题：

- 执行 `SELECT ... FOR UPDATE` 时，会加上 next-key lock。
- 如果有其他事务在锁范围内插入新记录，则该插入操作会被阻塞，从而避免幻读。

## 4. 隔离级别的实现机制

对于 **读提交** 和 **可重复读** 隔离级别的事务，它们通过 **Read View** 来实现，主要区别在于创建 Read View 的时机：

- **读提交**：每次 SELECT 都生成新的 Read View，因此同一事务期间多次读取同一数据，可能会出现不一致。
- **可重复读**：在事务启动时生成一个 Read View，整个事务期间使用同一视图，确保读到的数据都是事务启动前的记录。

这两个隔离级别的实现依赖于事务的 Read View 里的字段与记录中的两个隐藏列的比对，以控制并发事务对同一记录的访问。

## 5. 结论

在可重复读隔离级别中，普通的 SELECT 语句是基于 **MVCC** 实现的快照读，不加锁；而 `SELECT ... FOR UPDATE` 语句则是当前读，读取最新版本数据并加上 next-key lock 锁。通过这些机制，InnoDB 能够高效地处理并发事务，同时保持数据的一致性和完整性。


## 一句话总结undolog链条与mvcc:
每一行数据和对应的undolog结合之后就相当于，每一行数据都由其对应的undolog形成了一个逻辑上的历史版本链条，利用undo log回溯并获取特定的历史版本。


# MySQL 可重复读隔离级别与幻读问题

## 概述

- MySQL InnoDB引擎的默认隔离级别是「可重复读」，但这种隔离级别并没有完全解决幻读问题。

## 幻读定义

- 幻读发生在事务中，同一查询在不同时间产生不同结果集时。例如，两次执行SELECT语句，第二次返回了第一次未返回的行，该行称为“幻像”行。

## 幻读解决方案

### 快照读（普通select语句）

- 可重复读隔离级别通过MVCC避免了幻读。
- 事务开始后，执行第一个查询语句会创建一个Read View，后续查询利用这个Read View通过undo log版本链找到事务开始时的数据，保证了事务过程中每次查询的数据一致性。

### 当前读（select ... for update等语句）

- MySQL中除了普通查询是快照读，其他如update、insert、delete都是当前读，执行前会查询最新版本的数据。
- select ... for update这类查询语句会读取最新数据，并加上next-key lock（记录锁+间隙锁）避免幻读。

## 幻读未完全解决

- 尽管可重复读隔离级别在很大程度上避免了幻读，但仍存在个别情况无法解决。

## 幻读场景分析

### 第一个场景

- 事务A查询不存在的id=5的记录，事务B插入该记录并提交，事务A更新并查询到该记录，发生幻读。

### 第二个场景

- 事务A执行快照读得到3条记录，事务B插入id=200的记录并提交，事务A执行当前读得到4条记录，发生幻读。

## 总结

- MySQL InnoDB的可重复读隔离级别通过MVCC和next-key lock在很大程度上避免了幻读，但并未完全解决。
- 特殊场景下，建议在事务开始后立即执行select ... for update这类当前读语句，以避免幻读

# 锁



### 1. 全局锁

**使用方法：**

- 加锁命令：`FLUSH TABLES WITH READ LOCK`
- 释放锁命令：`UNLOCK TABLES`

**特点与应用：**

- 将整个数据库置为只读，阻止其他线程的增删改和表结构变更操作。
- 主要用于全库逻辑备份，确保备份期间数据一致性。

**缺点：**

- 备份期间数据库只读，可能导致业务停滞，影响性能。

**替代方案：**

- 对支持事务隔离级别为可重复读的存储引擎（如 InnoDB），使用 `mysqldump` 的 `--single-transaction` 参数，通过事务的 Read View 实现一致性备份，而不影响业务操作。

### 2. 表级锁

**类型包括：**

- **表锁**
    
    - **加锁方式：**
        - 共享锁（读锁）：`LOCK TABLES t_student READ;`
        - 独占锁（写锁）：`LOCK TABLES t_student WRITE;`
    - **释放锁：** `UNLOCK TABLES`
    - **注意事项：** 不推荐在 InnoDB 表上使用表锁，因为会影响并发性能，InnoDB 更适合行级锁。
- **元数据锁（MDL）**
    
    - 自动加锁，无需手动操作。
    - **作用：** 保证 CRUD 操作与表结构变更的互斥。
    - **释放时机：** 事务提交后。
    - **潜在问题：** 长事务可能导致表结构变更被阻塞，需避免长事务或及时终止。
- **意向锁**
    
    - **意向共享锁（IS）和意向独占锁（IX）**
    - **作用：** 快速判断表中是否存在行级锁，提升加锁效率。
    - **兼容性：** 不与行级锁冲突，仅与表级锁（共享/独占）冲突。
- **AUTO-INC 锁**
    
    - **作用：** 保证 `AUTO_INCREMENT` 字段值的连续递增。
    - **锁模式：**
        - 传统 AUTO-INC 锁：事务结束后释放。
        - 轻量级锁（MySQL 5.1.22+）：申请自增值后立即释放，提高并发性能。
    - **配置变量：** `innodb_autoinc_lock_mode` 控制锁模式。
    - **注意事项：** 配合 `binlog_format=row` 使用，避免主从复制数据不一致。

### 3. 行级锁（InnoDB 支持）

**类型包括：**

- **记录锁（Record Lock）**
    
    - 锁定单条记录，分为共享锁（S）和独占锁（X）。
    - **特点：** S 锁兼容 S 锁，不兼容 X 锁；X 锁不兼容任何锁。
- **间隙锁（Gap Lock）**
    
    - 锁定一个范围（不包含记录本身），防止幻读。
    - **特点：** 仅存在于可重复读隔离级别，锁之间兼容。
- **临键锁（Next-Key Lock）**
    
    - 结合记录锁和间隙锁，锁定范围及记录本身。
    - **特点：** 防止插入新记录到被锁定范围，提升一致性。
- **插入意向锁**
    
    - 特殊的间隙锁，表示有事务等待在某个区间插入记录。
    - **特点：** 防止多个事务在同一区间插入记录时发生冲突。

**锁定读操作：**

- `SELECT ... LOCK IN SHARE MODE;`（加共享锁）
- `SELECT ... FOR UPDATE;`（加独占锁）
- **注意事项：** 必须在事务中使用，如 `BEGIN` 或 `START TRANSACTION`。

### 总结

MySQL 提供多种锁机制以保障数据一致性和并发性能。全局锁适用于全库备份但影响业务，表级锁适用于需要锁定整个表的场景，行级锁则适用于高并发环境下的精细化控制。选择合适的锁类型和配置，能够有效提升数据库性能和稳定性。