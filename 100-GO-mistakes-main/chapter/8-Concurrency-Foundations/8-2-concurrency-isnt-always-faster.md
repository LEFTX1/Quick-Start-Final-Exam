## 8.2 并发并不总是更快

许多开发人员犯的一个常见误解是：并发解决方案应该总是比顺序解决方案更快，那就大错特错了。解决方案的整体性能取决于许多因素，例如我们程序整体架构的效率（并发性）、可以并行处理的部分，以及计算单元之间的竞争程度。在本节中，我们将介绍一些 Go 并发的基础知识；然后我们将看到一个具体的例子，其中并发解决方案不一定更快。

### 8.2.1 调度

线程是操作系统可以执行的最小处理单元。如果一个进程想要同时执行多个动作，它将启动多个线程。这些线程可以是：

* 当两个或多个线程可以启动、运行和运行时并发在重叠的时间段内完成。比如上一节中的服务员线程和咖啡机线程。
* 当同一任务是可以同时执行多次并行执行的。例如，多个服务员线程。

操作系统负责以最佳方式调度线程的进程，以便：

* 所有线程都可以消耗 CPU 周期，而不会产生太多等待时间(饥饿时间)。 
* 工作负载尽可能均匀地分布在不同的 CPU 内核之间

> **Note** 线程一词在 CPU 级别上也可以具有不同的含义。每个物理核可以由多个逻辑核（超线程的概念）组成，一个逻辑核也称为线程。在本节中，当我们使用线程一词时，它指的不是逻辑核心，而是处理单元的概念。

一个 CPU 核心执行不同的线程。当它从一个线程切换到另一个线程时，它会执行一项称为上下文切换的操作。消耗 CPU 周期的活动线程处于 *执行* 状态并移动到 *可运行* 状态，这意味着准备执行但等待可用内核。上下文切换被认为是一项昂贵的操作，因为操作系统需要在切换之前保存线程的当前执行状态（例如，当前寄存器值）。

作为 Go 开发者，我们不能直接创建线程，但是可以创建 goroutine，可以认为是应用级线程。但是，如果 OS 线程由 OS 上下文切换打开和关闭 CPU 内核，则 goroutine 由 Go 运行时上下文切换打开和关闭 OS 线程。

此外，与 OS 线程相比，goroutine 的内存占用更小：Go 1.4 的 goroutines 为 2 KB，OS 线程取决于 OS，但例如，在Linux/x86‑32 上，默认大小为 2 MB。占用更小的内存使得上下文切换也更快。

> **Note** 根据实际测试得出，上下文切换 goroutine 比线程的速度大约快 80% 到 90%。

现在让我们深入研究 Go 调度程序的工作原理，以概述 goroutine 的处理方式。

在内部，Go 调度器使用以下术语：

* G:协程 goroutine
* M:操作系统线程（代表机器）
* P:CPU核心（代表处理器）

每个 OS 线程 (M) 由 OS 调度程序分配给一个 CPU 内核 (P)。然后，每个 goroutine (G) 在一个 OS 线程 (M) 上运行。`GOMAXPROCS` 变量定义了负责同时执行用户级代码的操作系统线程 (M) 的限制。然而，如果线程在系统调用（例如 I/O）中被阻塞，调度程序可以启动更多操作系统线程 (M)。从 Go 1.5 开始，`GOMAXPROCS` 默认等于可用 CPU 内核的数量。

goroutine 的生命周期比 OS 线程更简单。它可以是：

* 执行中(Executing):goroutine 被调度在一个 M 上并执行它的指令
* 待执行(Runnable):等待被置为执行状态 
* 排队中(Waiting):停止并等待某事完成，例如系统调用或同步操作（例如，互斥锁(mutex)）

关于 Go 调度实现的最后一个阶段是：当一个 goroutine 被创建但还不能执行时。例如，所有其他 M 已经在执行 G。在这种情况下，Go 运行时将如何处理它？答案是排队。事实上，Go 运行时处理两种队列：每个 P 一个本地队列和一个在所有 P 之间共享的全局队列。

我们将研究 4 核机器上的调度情况，`GOMAXPROCS` 等于4. 不同的部分是逻辑核心 (P)、goroutines (G)、OS 线程 (M)、本地队列和全局队列：

![](https://img.exciting.net.cn/20221220182146.png)

首先，我们可以注意到 5 M，而 `GOMAXPROCS` 设置为 4。然而，正如我们提到的，如果有必要，Go 运行时可以创建比 `GOMAXPROCS` 值更多的操作系统线程。

P0、P1 和 P3 目前正忙于执行 Go 运行时线程。然而，由于 M3 关闭 P2，P2 目前处于空闲状态，并且没有要执行的 goroutine。这不是一个好的情况，因为总共有六个可运行的 goroutine 等待执行。一些在全局队列中，一些在其他本地队列中。Go 运行时将如何处理这种情况？下面是调度实现的伪代码：

```go
runtime.schedule() {
    // Only 1/61 of the time, check the global runnable queue for a G.
    // If not found, check the local queue.
    // If not found,
    //     Try to steal from other Ps.
    //     If not, check the global runnable queue.
    //     If not found, poll network.
    }
```

每执行 1/61，Go 调度程序将检查全局队列中的 goroutine 是否可用。如果没有，它将检查本地队列。同时，如果全局队列和本地队列都为空，它可以从其他本地队列中提取 goroutine。这种调度原则称为工作窃取，它允许未充分利用的处理器主动寻找其他处理器的 goroutine 并 *窃取* 一些。

最后一件重要的事情要提到，在 Go 1.14 之前，调度程序是协作的，这意味着 goroutine 只能在特定的阻塞情况下（例如，通道发送或接收、I/O、等待 mutex）。从 Go 1.14 开始，Go 调度程序现在是抢占式的。这意味着当一个 goroutine 运行特定的时间量（10 毫秒）时，它将被标记为可抢占的，并且可以上下文切换到另一个 goroutine 替换。需要长时间运行的任务可以强制共享 CPU 时间。

现在我们已经了解了 Go 中调度的基础知识，让我们深入研究一个具体示例：以并行方式实现归并排序。

### 8.2.2 并行归并排序

首先，让我们简要回顾一下归并排序算法的工作原理。然后，我们将实现一个并行版本。请注意，范围不是实现最有效的版本，而是支持一个具体的例子来说明为什么并发并不总是更快。

归并排序算法的工作原理是将一个列表重复分解为两个子列表，直到每个子列表包含一个元素，然后合并这些子列表，从而得到一个排序列表：

![](https://img.exciting.net.cn/48.png)

每个拆分操作将一个列表拆分为两个子列表，而合并操作将两个子列表合并为一个排序列表。

这是该算法的顺序实现。我们不会编写整个代码，因为它不是本节的重点：

```go
func sequentialMergesort(s []int) {
    if len(s) <= 1 {
        return
    }

    middle := len(s) / 2
    sequentialMergesort(s[:middle])
    sequentialMergesort(s[middle:])
    merge(s, middle)
}

func merge(s []int, middle int) {
    // ...
}
```

该算法具有使其对并发开放的结构。实际上，由于每个 `sequentialMergesort` 操作都在不需要完全复制的独立数据集上工作（这里是使用切片的底层数组的独立视图），我们可以通过启动每个 `sequentialMergesort` 在 CPU 内核之间分配这个工作负载在不同的 goroutine 中操作。让我们编写第一个并行实现：

```go
func parallelMergesortV1(s []int) {
    if len(s) <= 1 {
        return
    }

    middle := len(s) / 2
    var wg sync.WaitGroup
    wg.Add(2)
    
    go func() {
        defer wg.Done()
        parallelMergesortV1(s[:middle])
    }()
    
    go func() {
        defer wg.Done()
        parallelMergesortV1(s[middle:])
    }()
    
    wg.Wait()
    merge(s, middle)
}
```

在这个版本中，工作负载的每一半都在一个单独的 goroutine 中处理。父 goroutine 使用 `sync.WaitGroup` 等待两个部分在合并操作之前执行。

> **Note** 如果您还不熟悉 `sync.WaitGroup`，我们将在 _sync.WaitGroup的误用_ 中深入研究。简而言之，它允许等待 _n_ 个操作完成；通常，goroutines 就像前面的例子一样。

我们现在有了合并排序算法的并行版本。因此，如果我们运行一个基准来比较这个版本和顺序版本，并行版本应该更快，对吗？让我们在具有 10k 个元素的 4 核机器上运行它：

```shell
Benchmark_sequentialMergesort-4 2278993555 ns/op
Benchmark_parallelMergesortV1-4 17525998709 ns/op
```

令人惊讶的是，并行版本几乎慢了一个数量级。我们如何解释这个结果？将工作负载分布在四个内核上的并行版本怎么可能比在单台机器上运行的顺序版本慢？我们来分析问题。

如果我们有一个切片，比如 1024 个元素，父 goroutine 将启动两个 goroutine，每个负责处理由 512 个元素组成的一半。然后，这些 goroutine 中的每一个都会启动两个新的 goroutine 来负责处理 256 个元素。然后是 128，以此类推，直到我们启动一个 goroutine 来计算单个元素。

如果我们想要并行化的工作负载太小，意味着我们要计算得太快，那么跨核分配作业的好处就会被破坏。事实上，与直接合并当前 goroutine 中的少量项目相比，创建 goroutine 并让调度程序执行它所花费的时间太长了。虽然 goroutines 是轻量级的，启动起来比线程快，但我们仍然会面临工作量太小的情况。

> **Note** 我们将在不使用 Go 诊断工具中讨论如何更深入地了解何时执行的并行性不佳。

那么我们怎样才能克服这个结果呢？是不是意味着归并排序算法不能并行化？等等，没那么快。

让我们尝试另一种方法。因为在一个新的 goroutine 中合并少量元素效率不高，让我们定义一个阈值。这个阈值将表示以并行方式处理它应该有多大的一半。如果一半低于这个值，我们将按顺序处理。下面是一个新版本：

```go
const max = 2048
    
func parallelMergesortV2(s []int) {
    if len(s) <= 1 {
        return
    }

    if len(s) <= max {
        sequentialMergesort(s)
    } else {
        middle := len(s) / 2

        var wg sync.WaitGroup
        wg.Add(2)

        go func() {
            defer wg.Done()
            parallelMergesortV2(s[:middle])
        }()

        go func() {
            defer wg.Done()
            parallelMergesortV2(s[middle:])
        }()
        
        wg.Wait()
        merge(s, middle)
    }
}
```

如果该值小于 max，我们称为顺序版本。否则，我们将继续调用我们的并行实现。对结果有影响吗？是的，它确实：

```shell
Benchmark_sequentialMergesort-4 2278993555 ns/op
Benchmark_parallelMergesortV1-4 17525998709 ns/op
Benchmark_parallelMergesortV2-4 1313010260 ns/op
```

我们的 v2 并行实现比顺序实现快 40% 以上，这要归功于定义阈值以指示何时并行应该比顺序更有效。

> **Note** 为什么我将阈值设置为 2048？这是我机器上这个特定工作负载的最佳值。通常，应该使用基准（在与生产类似的执行环境中运行）仔细定义此类魔术值。
> 
> 另一件事，很有趣的是，在没有实现 goroutine 概念的编程语言上运行相同的算法会对值产生影响。实际上，使用线程在 Java 中运行相同的示例意味着更接近 8192 的最佳值。这进一步证明了 goroutine 比线程更高效。

我们在本章中看到了 Go 中调度的基本概念：线程和 goroutine 之间的区别以及 Go 运行时如何调度 goroutine。同时，使用并行归并排序示例，我们说明了并发性不一定总是更快。正如我们所看到的，当我们启动 goroutine 以处理最小的工作量（仅合并一小部分元素）时，我们可以从并行性中获得的好处正在被破坏。

那么，我们应该怎么选择呢？首先，我们必须记住，并发并不总是更快，不应该被认为是解决所有问题的默认方法。首先，它使事情变得更加复杂。此外，现代 CPU 在执行顺序代码和可预测代码方面变得异常高效。例如，超标量处理器可以在单个内核上以高效率并行执行指令。

这是否意味着我们不应该使用并发？当然不是。但是，必须牢记这些结论。如果我们不确定并行版本是否会更快，也许正确的方法是首先从一个简单且顺序的版本开始，并从这里构建，这要归功于分析（_不使用 Go 诊断工具_）和基准测试（_编写不准确的基准测试_）。它可能是确保值得使用并发的唯一方法。

下一节将讨论一个非常常见的问题：何时使用通道或互斥锁？